{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IS4J8PALgJGI"
   },
   "source": [
    "## 參考   \n",
    "\n",
    "1.  [文本情感分类（三）：分词 OR 不分词]( https://kexue.fm/archives/3863), LSTM model 但是跑出來不像 blog 所述\n",
    "2.  [当Bert遇上Keras：这可能是Bert最简单的打开姿势]( https://kexue.fm/archives/6736)\n",
    "\n",
    "1.   keras-bert：https://github.com/CyberZHG/keras-bert\n",
    "\n",
    "1.   更多例子所在Github：https://github.com/bojone/bert_in_keras/\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30431,
     "status": "ok",
     "timestamp": 1569847316226,
     "user": {
      "displayName": "Patrick Ruan",
      "photoUrl": "",
      "userId": "12739963325559255992"
     },
     "user_tz": -480
    },
    "id": "WEXMSTO-fSzt",
    "outputId": "6978c3c6-60ad-4001-b98c-11f8c9e18679"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "root = 'drive/My Drive/'\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 961
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45678,
     "status": "ok",
     "timestamp": 1569847331514,
     "user": {
      "displayName": "Patrick Ruan",
      "photoUrl": "",
      "userId": "12739963325559255992"
     },
     "user_tz": -480
    },
    "id": "6jXiEuIgf1ht",
    "outputId": "9f1207fc-4532-4937-ec40-aeed7bb2c57e"
   },
   "source": [
    "colabok= root + 'ColabOK/'\n",
    "!pip install keras_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48191,
     "status": "ok",
     "timestamp": 1569847334058,
     "user": {
      "displayName": "Patrick Ruan",
      "photoUrl": "",
      "userId": "12739963325559255992"
     },
     "user_tz": -480
    },
    "id": "V1gE5DSLeUN2",
    "outputId": "e8b9aac4-3852-4a15-fde0-1eb06512b01f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#! -*- coding:utf-8 -*-\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "from keras_bert import load_trained_model_from_checkpoint, Tokenizer\n",
    "import re, os\n",
    "import codecs\n",
    "\n",
    "\n",
    "maxlen = 100\n",
    "config_path ='cbert1/chinese_L-12_H-768_A-12/bert_config.json'\n",
    "checkpoint_path = 'cbert1/chinese_L-12_H-768_A-12/bert_model.ckpt'\n",
    "dict_path = 'cbert1/chinese_L-12_H-768_A-12/vocab.txt'\n",
    "\n",
    "\n",
    "token_dict = {}\n",
    "\n",
    "with codecs.open(dict_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        token_dict[token] = len(token_dict)\n",
    "\n",
    "\n",
    "class OurTokenizer(Tokenizer):\n",
    "    def _tokenize(self, text):\n",
    "        R = []\n",
    "        for c in text:\n",
    "            if c in self._token_dict:\n",
    "                R.append(c)\n",
    "            elif self._is_space(c):\n",
    "                R.append('[unused1]') # space类用未经训练的[unused1]表示\n",
    "            else:\n",
    "                R.append('[UNK]') # 剩余的字符是[UNK]\n",
    "        return R\n",
    "\n",
    "tokenizer = OurTokenizer(token_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 156320,
     "status": "ok",
     "timestamp": 1569847442254,
     "user": {
      "displayName": "Patrick Ruan",
      "photoUrl": "",
      "userId": "12739963325559255992"
     },
     "user_tz": -480
    },
    "id": "8-GcpFJDpA-o",
    "outputId": "1d7dfd58-b192-42c4-bd27-82e1b110693d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "bert_model = load_trained_model_from_checkpoint(config_path, checkpoint_path, seq_len=None)\n",
    "\n",
    "for l in bert_model.layers:\n",
    "    l.trainable = True\n",
    "\n",
    "x1_in = Input(shape=(None,))\n",
    "x2_in = Input(shape=(None,))\n",
    "\n",
    "x = bert_model([x1_in, x2_in])\n",
    "x = Lambda(lambda x: x[:, 0])(x)\n",
    "p = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model([x1_in, x2_in], p)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(1e-5), # 用足够小的学习率\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "h5_path = 'cbert1/05_02F2.h5'\n",
    "model.load_weights(h5_path)\n",
    "model._make_predict_function()  # amazing  https://github.com/keras-team/keras/issues/6462"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [02/Oct/2019 01:57:36] \"\u001b[37mPOST /callback HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Oct/2019 01:57:44] \"\u001b[37mPOST /callback HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Oct/2019 01:59:30] \"\u001b[37mPOST /callback HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Oct/2019 01:59:57] \"\u001b[37mPOST /callback HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Oct/2019 02:00:19] \"\u001b[37mPOST /callback HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Oct/2019 02:00:30] \"\u001b[37mPOST /callback HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Oct/2019 02:00:40] \"\u001b[37mPOST /callback HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Oct/2019 02:00:54] \"\u001b[37mPOST /callback HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Oct/2019 02:01:00] \"\u001b[37mPOST /callback HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "def sentence_inference(x):\n",
    "  test = x\n",
    "  maxlen =100\n",
    "  d=[test,0]\n",
    "  test=d[0][:maxlen]\n",
    "  x1, x2 = tokenizer.encode(first=str(test))\n",
    "  x1=[x1]\n",
    "  x2=[x2]\n",
    "  test =[x1, x2]\n",
    "  model.predict(test)\n",
    "  if model.predict(test) >=0.5:\n",
    "    y = 1\n",
    "  else: y=0\n",
    "  #print(f'{x} \\n {y}')\n",
    "  return y, model.predict(test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#!pip install line-bot-sdk\n",
    "\n",
    "from flask import Flask, request, abort\n",
    "import json\n",
    "\n",
    "from linebot import (\n",
    "    LineBotApi, WebhookHandler\n",
    ")\n",
    "from linebot.exceptions import (\n",
    "    InvalidSignatureError\n",
    ")\n",
    "from linebot.models import (\n",
    "    MessageEvent, TextMessage, TextSendMessage,\n",
    ")\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "#token\n",
    "line_bot_api = LineBotApi('4UMZ57VIP0FSCa62WsYUUHwQ/KlZBNcyNTEzuOlyAfaIOMPjGSJKyAf4P6KDg8d1kHwImrxNg3fcXvIjxpioTu8OkQKbfI0lsiVcQ9BzkcLt0VkrRLfwgvSsS9wzAxnn48ZPjXHGXUYwUgWrPukIbgdB04t89/1O/w1cDnyilFU=')\n",
    "#secret\n",
    "handler = WebhookHandler('182080c576d83b01a786616b8abd1b33')\n",
    "\n",
    "@app.route(\"/callback\", methods=['POST'])\n",
    "def callback():\n",
    "    # get X-Line-Signature header value\n",
    "    signature = request.headers['X-Line-Signature']\n",
    "\n",
    "    # get request body as text\n",
    "    body = request.get_data(as_text=True)\n",
    "    data = json.loads(body)\n",
    "    y, s = sentence_inference(data['events'][0]['message']['text'])\n",
    "    if y == 1:\n",
    "        y = \"正面評價\"\n",
    "    else: y = \"負評\"\n",
    "    \n",
    "    app.logger.info(\"Request body: \" + body)\n",
    "    try:\n",
    "        line_bot_api.reply_message(data['events'][0]['replyToken'], TextSendMessage(text=y))\n",
    "        #print('2')\n",
    "\n",
    "    except InvalidSignatureError:\n",
    "        #print('pre_3')\n",
    "        abort(400)\n",
    "        #print('3')\n",
    "\n",
    "    return 'OK'\n",
    "\n",
    "\n",
    "@handler.add(MessageEvent, message=TextMessage)\n",
    "def handle_message(event):\n",
    "    print('2_call')\n",
    "    print(event)\n",
    "    line_bot_api.reply_message(\n",
    "        event.reply_token,\n",
    "        TextSendMessage(text=event.message.text))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #app.run()\n",
    "    app.run(host='0.0.0.0', port=8080, threaded=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZayET5ebEI41"
   },
   "source": [
    "# 底下是研究過程中對 Input format 的研究\n",
    "## 研究  Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 157812,
     "status": "ok",
     "timestamp": 1569847443798,
     "user": {
      "displayName": "Patrick Ruan",
      "photoUrl": "",
      "userId": "12739963325559255992"
     },
     "user_tz": -480
    },
    "id": "38zJF3LLeBz9",
    "outputId": "e7bc1f07-b15b-4cfc-eec5-32157882cdd2"
   },
   "source": [
    "#\n",
    "\n",
    "\n",
    "test = ' 作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产率？为什么在文化上有着深刻纽带关系的中国和日本却在经济发展上有着极大的差异？为什么英国的北美殖民地造就了经济强大的美国，而西班牙的北美殖民却造就了范后的墨西哥？……很有价值，但不包括【中国近代史专业】。螢幕閱讀器支援功能已啟用'\n",
    "len(test) #160\n",
    "maxlen #100\n",
    "d = [test,0]\n",
    "test = d[0][:maxlen]\n",
    "#test = test[:maxlen]\n",
    "#test =[test]\n",
    "print(test)\n",
    "print(f'len of test = {len(test)}')\n",
    "#print(f'test[0][0] is {test[3]}')\n",
    "#test = test[:100]\n",
    "x1,x2=tokenizer.encode(first=str(test))\n",
    "#X1=seq_padding(x1)\n",
    "#X2=seq_padding(x2)\n",
    "x1=[x1]\n",
    "x2=[x2]\n",
    "test=[x1,x2]\n",
    "print(type(x1))\n",
    "print(type(test))  #str\n",
    "print(len(test))   #2\n",
    "#maxlen #100\n",
    "print(len(x1))  #102\n",
    "print(len(x2))  #102\n",
    "#x2  # all \"0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xb7PiFcBErAx"
   },
   "source": [
    "# 製作 function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-03qKOAQEUH_"
   },
   "source": [
    "# 測試句子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVLP8uyTEou_"
   },
   "source": [
    "def sentence_inference(x):\n",
    "  test = x\n",
    "  maxlen =100\n",
    "  d=[test,0]\n",
    "  test=d[0][:maxlen]\n",
    "  x1, x2 = tokenizer.encode(first=str(test))\n",
    "  x1=[x1]\n",
    "  x2=[x2]\n",
    "  test =[x1, x2]\n",
    "  model.predict(test)\n",
    "  if model.predict(test) >=0.5:\n",
    "    y = 1\n",
    "  else: y=0\n",
    "  print(f'{x} \\n {y}')\n",
    "  return y, model.predict(test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 160447,
     "status": "ok",
     "timestamp": 1569847446520,
     "user": {
      "displayName": "Patrick Ruan",
      "photoUrl": "",
      "userId": "12739963325559255992"
     },
     "user_tz": -480
    },
    "id": "nRx_iRCyC7bl",
    "outputId": "c6905a79-89cb-4ba3-a435-b88811eb2387"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持一...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持一...\n",
       "1  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...\n",
       "2  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...\n",
       "3  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...\n",
       "4  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_neg = 'cbert1/neg.xls'\n",
    "f_pos = \"cbert1/pos.xls\"\n",
    "neg = pd.read_excel(f_neg, header=None)\n",
    "pos = pd.read_excel(f_pos, header=None)\n",
    "pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 844,
     "status": "ok",
     "timestamp": 1569848038011,
     "user": {
      "displayName": "Patrick Ruan",
      "photoUrl": "",
      "userId": "12739963325559255992"
     },
     "user_tz": -480
    },
    "id": "lLQGFryQI_ug",
    "outputId": "e964b2ae-5f18-4ce0-a705-88a1bdc676ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作者很棒, 我很贊同,沒有列舉的方法很實用 \n",
      " 0\n",
      "作者很棒,列舉的方法很實用ㄝ \n",
      " 1\n",
      "作者很棒, 我很贊同,列舉的方法很實用ㄝ \n",
      " 0\n",
      "作者很棒, 我很贊同,沒有列舉的方法很實用 \n",
      " 0\n",
      "作者很棒,列舉的方法很實用ㄝ \n",
      " 1\n",
      "作者很棒, 我很贊同,列舉的方法很實用ㄝ \n",
      " 0\n",
      "0 [[0.3782348]]\n",
      "作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延续，没有战后的民发反思，没有～，就不会让日本成为一个经济强国．当然，美国人也给日本人带来了耻辱．对日中关系也造成了深远的影响．文中揭露了＂东京审判＂中很多鲜为人知的东西．让人惊醒．唉！中国人民对日本的了解是不是太少了． \n",
      " 1\n",
      "装XP非常麻烦，需要准备外置软驱，给光驱及南桥装驱动。官方没有驱动下载。只有打客服电话要他们发给你。尤其声卡，极其麻烦。建议菜鸟要装XP不要买这机子。装Vista的没问题。 \n",
      " 0\n",
      "王蜀黍：今天有幸能参加蒙牛举办的三人篮球赛，“客队”第一个亮相，经过一天的比赛，终于闯进了6强，等待我们的是明天与其他学校的对决，加油！——同意：11人 http:t.cn/zjh516R （分享自 @深大小评论） \n",
      " 1\n",
      "这本书好畅销啊,虽然平时不大喜欢看这方面内容的书,但在当当上看到这么多推荐读它的评论,也忍不住买一本来读读看了 \n",
      " 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, array([[0.00019237]], dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_inference(x):\n",
    "  test = x\n",
    "  maxlen =100\n",
    "  d=[test,0]\n",
    "  test=d[0][:maxlen]\n",
    "  x1, x2 = tokenizer.encode(first=str(test))\n",
    "  x1=[x1]\n",
    "  x2=[x2]\n",
    "  test =[x1, x2]\n",
    "  model.predict(test)\n",
    "  if model.predict(test) >=0.5:\n",
    "    y = 1\n",
    "  else: y=0\n",
    "  print(f'{x} \\n {y}')\n",
    "  return y, model.predict(test)\n",
    "\n",
    "#model.predict(input_transform('作者很棒, 我很贊同,所列舉的方法很實用'))\n",
    "sentence_inference('作者很棒, 我很贊同,沒有列舉的方法很實用')\n",
    "sentence_inference('作者很棒,列舉的方法很實用ㄝ')\n",
    "sentence_inference('作者很棒, 我很贊同,列舉的方法很實用ㄝ')\n",
    "sentence_inference('作者很棒, 我很贊同,沒有列舉的方法很實用')\n",
    "sentence_inference('作者很棒,列舉的方法很實用ㄝ')\n",
    "y, s=sentence_inference('作者很棒, 我很贊同,列舉的方法很實用ㄝ')\n",
    "print(y, s)\n",
    "sentence_inference(pos.iloc[3,0])\n",
    "sentence_inference(neg.iloc[7833,0])\n",
    "sentence_inference(pos.iloc[8383,0])\n",
    "sentence_inference(neg.iloc[173,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRY"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "05_02F3_CBERT_load_weights_ColabOK.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
